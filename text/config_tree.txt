CONFIG
├── mode
│   └── generate_reflow_data                                                                                                                                                                                                                                         
├── is_di4c
│   └── False                                                                                                                                                                                                                                                        
├── seed
│   └── 1                                                                                                                                                                                                                                                            
├── loader
│   └── global_batch_size: 512                                                                                                                                                                                                                                       
│       eval_global_batch_size: 512                                                                                                                                                                                                                                  
│       batch_size: 20                                                                                                                                                                                                                                               
│       eval_batch_size: 20                                                                                                                                                                                                                                          
│       num_workers: 112                                                                                                                                                                                                                                             
│       pin_memory: true                                                                                                                                                                                                                                             
│                                                                                                                                                                                                                                                                    
├── sampling
│   └── predictor: ancestral                                                                                                                                                                                                                                         
│       steps: 1024                                                                                                                                                                                                                                                  
│       noise_removal: greedy                                                                                                                                                                                                                                        
│       use_float64: true                                                                                                                                                                                                                                            
│       p_nucleus: 1.0                                                                                                                                                                                                                                               
│       num_sample_batches: 2                                                                                                                                                                                                                                        
│       num_sample_log: 2                                                                                                                                                                                                                                            
│       semi_ar: false                                                                                                                                                                                                                                               
│       stride_length: 1                                                                                                                                                                                                                                             
│       num_strides: 1                                                                                                                                                                                                                                               
│       num_reflow_samples: 20000                                                                                                                                                                                                                                    
│       temperature: 1.0                                                                                                                                                                                                                                             
│                                                                                                                                                                                                                                                                    
├── training
│   └── ema: 0.9999                                                                                                                                                                                                                                                  
│       antithetic_sampling: true                                                                                                                                                                                                                                    
│       importance_sampling: false                                                                                                                                                                                                                                   
│       sampling_eps: 0.001                                                                                                                                                                                                                                          
│       change_of_variables: false                                                                                                                                                                                                                                   
│       loss_precision: bf16                                                                                                                                                                                                                                         
│       finetune_path: ''                                                                                                                                                                                                                                            
│                                                                                                                                                                                                                                                                    
├── eval
│   └── checkpoint_path: /data3/wjhj16/ReDi/text/checkpoints/redi1.ckpt                                                                                                                                                                                              
│       disable_ema: false                                                                                                                                                                                                                                           
│       compute_generative_perplexity: true                                                                                                                                                                                                                          
│       perplexity_batch_size: 8                                                                                                                                                                                                                                     
│       compute_perplexity_on_sanity: false                                                                                                                                                                                                                          
│       gen_ppl_eval_model_name_or_path: gpt2-large                                                                                                                                                                                                                  
│       generate_samples: true                                                                                                                                                                                                                                       
│       generated_samples_path: /data3/wjhj16/ReDi/text/samples.json                                                                                                                                                                                                 
│                                                                                                                                                                                                                                                                    
├── optim
│   └── weight_decay: 0                                                                                                                                                                                                                                              
│       lr: 0.0003                                                                                                                                                                                                                                                   
│       beta1: 0.9                                                                                                                                                                                                                                                   
│       beta2: 0.999                                                                                                                                                                                                                                                 
│       eps: 1.0e-08                                                                                                                                                                                                                                                 
│       ln_tune: none                                                                                                                                                                                                                                                
│                                                                                                                                                                                                                                                                    
├── trainer
│   └── _target_: lightning.Trainer                                                                                                                                                                                                                                  
│       accelerator: cuda                                                                                                                                                                                                                                            
│       num_nodes: 1                                                                                                                                                                                                                                                 
│       devices: 4                                                                                                                                                                                                                                                   
│       accumulate_grad_batches: 7                                                                                                                                                                                                                                   
│       gradient_clip_val: 1.0                                                                                                                                                                                                                                       
│       precision: '32'                                                                                                                                                                                                                                              
│       num_sanity_val_steps: 2                                                                                                                                                                                                                                      
│       max_steps: 1000000                                                                                                                                                                                                                                           
│       log_every_n_steps: 100                                                                                                                                                                                                                                       
│       limit_train_batches: 1.0                                                                                                                                                                                                                                     
│       limit_val_batches: 1.0                                                                                                                                                                                                                                       
│       val_check_interval: 5000                                                                                                                                                                                                                                     
│                                                                                                                                                                                                                                                                    
├── wandb
│   └── project: flow-ode                                                                                                                                                                                                                                            
│       notes: Flow ODEs for UDLM                                                                                                                                                                                                                                    
│       group: null                                                                                                                                                                                                                                                  
│       job_type: null                                                                                                                                                                                                                                               
│       name: duo-owt                                                                                                                                                                                                                                                
│       id: duo-owt_1                                                                                                                                                                                                                                                
│       tags:                                                                                                                                                                                                                                                        
│       - log-linear                                                                                                                                                                                                                                                 
│       - reflow-dataset                                                                                                                                                                                                                                             
│       - openwebtext-valid                                                                                                                                                                                                                                          
│       - duo                                                                                                                                                                                                                                                        
│       offline: true                                                                                                                                                                                                                                                
│                                                                                                                                                                                                                                                                    
├── checkpointing
│   └── save_dir: /data3/wjhj16/ReDi/text                                                                                                                                                                                                                            
│       resume_from_ckpt: true                                                                                                                                                                                                                                       
│       resume_ckpt_path: /data3/wjhj16/ReDi/text/checkpoints/last.ckpt                                                                                                                                                                                              
│                                                                                                                                                                                                                                                                    
├── callbacks
│   └── checkpoint_every_n_steps:                                                                                                                                                                                                                                    
│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                                                                                                                                                                                                      
│         save_top_k: -1                                                                                                                                                                                                                                             
│         save_last: true                                                                                                                                                                                                                                            
│         dirpath: /data3/wjhj16/ReDi/text/checkpoints                                                                                                                                                                                                               
│         verbose: true                                                                                                                                                                                                                                              
│         auto_insert_metric_name: false                                                                                                                                                                                                                             
│         every_n_train_steps: 500                                                                                                                                                                                                                                   
│       checkpoint_monitor:                                                                                                                                                                                                                                          
│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                                                                                                                                                                                                      
│         monitor: val/nll                                                                                                                                                                                                                                           
│         mode: min                                                                                                                                                                                                                                                  
│         save_top_k: 1                                                                                                                                                                                                                                              
│         save_last: false                                                                                                                                                                                                                                           
│         dirpath: /data3/wjhj16/ReDi/text/checkpoints                                                                                                                                                                                                               
│         filename: best                                                                                                                                                                                                                                             
│         auto_insert_metric_name: false                                                                                                                                                                                                                             
│         verbose: true                                                                                                                                                                                                                                              
│       learning_rate_monitor:                                                                                                                                                                                                                                       
│         _target_: lightning.pytorch.callbacks.LearningRateMonitor                                                                                                                                                                                                  
│         logging_interval: step                                                                                                                                                                                                                                     
│                                                                                                                                                                                                                                                                    
├── data
│   └── train: reflow-dataset                                                                                                                                                                                                                                        
│       valid: openwebtext-valid                                                                                                                                                                                                                                     
│       tokenizer_name_or_path: gpt2                                                                                                                                                                                                                                 
│       wrap: true                                                                                                                                                                                                                                                   
│       streaming: false                                                                                                                                                                                                                                             
│       insert_train_eos: true                                                                                                                                                                                                                                       
│       insert_valid_eos: true                                                                                                                                                                                                                                       
│       cache_dir: CACHE_DIR                                                                                                                                                                                                                                         
│                                                                                                                                                                                                                                                                    
├── model
│   └── name: small                                                                                                                                                                                                                                                  
│       type: ddit                                                                                                                                                                                                                                                   
│       hidden_size: 768                                                                                                                                                                                                                                             
│       cond_dim: 128                                                                                                                                                                                                                                                
│       length: 1024                                                                                                                                                                                                                                                 
│       n_blocks: 12                                                                                                                                                                                                                                                 
│       n_heads: 12                                                                                                                                                                                                                                                  
│       scale_by_sigma: true                                                                                                                                                                                                                                         
│       dropout: 0.1                                                                                                                                                                                                                                                 
│       tie_word_embeddings: false                                                                                                                                                                                                                                   
│       vocab_lookup: true                                                                                                                                                                                                                                           
│                                                                                                                                                                                                                                                                    
├── strategy
│   └── _target_: lightning.pytorch.strategies.DDPStrategy                                                                                                                                                                                                           
│       find_unused_parameters: false                                                                                                                                                                                                                                
│                                                                                                                                                                                                                                                                    
├── noise
│   └── type: log-linear                                                                                                                                                                                                                                             
│       parameterization: log-linear                                                                                                                                                                                                                                 
│       eps: 0                                                                                                                                                                                                                                                       
│       denoiser_latent_conditioning: -1                                                                                                                                                                                                                             
│       freeze_encoder: false                                                                                                                                                                                                                                        
│       freeze_decoder: false                                                                                                                                                                                                                                        
│                                                                                                                                                                                                                                                                    
├── lr_scheduler
│   └── _target_: transformers.get_constant_schedule_with_warmup                                                                                                                                                                                                     
│       num_warmup_steps: 2500                                                                                                                                                                                                                                       
│                                                                                                                                                                                                                                                                    
├── prior
│   └── type: none                                                                                                                                                                                                                                                   
│       latent_width: 0                                                                                                                                                                                                                                              
│       latent_height: 0                                                                                                                                                                                                                                             
│                                                                                                                                                                                                                                                                    
└── algo
    └── name: duo                                                                                                                                                                                                                                                    
        backbone: dit                                                                                                                                                                                                                                                
        parameterization: mean                                                                                                                                                                                                                                       
        time_conditioning: true                                                                                                                                                                                                                                      
        T: 0                                                                                                                                                                                                                                                         
        subs_masking: false                                                                                                                                                                                                                                          
        causal_attention: false                                                                                                                                                                                                                                      
        gumbel_tau_log10_start: -3.0                                                                                                                                                                                                                                 
        gumbel_tau_log10_end: -3.0                                                                                                                                                                                                                                   
        curriculum_start: 0                                                                                                                                                                                                                                          
        curriculum_end: 500000                                                                                                                                                                                                                                       
        integral_cache_path: /data3/wjhj16/ReDi/text/integral/gpt2.pkl                                                                                                                                                                                               
        loss_type: elbo                                                                                                                                                                                                                                              
        ignore_bos: false                                                                                                                                                                                                                                            
        gamma_min: -3.55                                                                                                                                                                                                                                             
        gamma_max: -1.85                                                                                                                                                                                                                                             
                                                                                                                                                                                                                                                                     
